#!/usr/bin/env python3
"""
Morning Report News Fetcher
è‡ªåŠ¨è·å–å›½å†…å¤– AI æœ€æ–°èµ„è®¯
"""

import json
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional
import re

class NewsFetcher:
    def __init__(self, config_path: str = None):
        if config_path is None:
            config_path = Path(__file__).parent / "sources.json"
        
        with open(config_path, "r", encoding="utf-8") as f:
            self.config = json.load(f)
        
        self.report_config = self.config.get("report_config", {})
        self.lookback_hours = self.report_config.get("lookback_hours", 24)
        
    def fetch_techcrunch_feed(self) -> List[Dict]:
        """æŠ“å– TechCrunch AI Feed"""
        try:
            feed_url = "https://techcrunch.com/category/artificial-intelligence/feed/"
            response = requests.get(feed_url, timeout=10)
            response.raise_for_status()
            
            # Parse RSS XML
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.content)
            
            news_items = []
            # RSS 2.0 namespace
            ns = {'content': 'http://purl.org/rss/1.0/modules/content/'}
            
            for item in root.findall('.//item'):
                title = item.find('title')
                link = item.find('link')
                pub_date = item.find('pubDate')
                description = item.find('description')
                
                if title is not None:
                    news_items.append({
                        "title": title.text.strip() if title.text else "",
                        "link": link.text if link is not None else "",
                        "pub_date": pub_date.text if pub_date is not None else "",
                        "description": description.text.strip() if description is not None and description.text else "",
                        "source": "TechCrunch"
                    })
            
            return news_items[:5]  # Top 5
        except Exception as e:
            print(f"Error fetching TechCrunch: {e}")
            return []
    
    def fetch_url_content(self, url: str, max_chars: int = 3000) -> str:
        """é€šç”¨ç½‘é¡µå†…å®¹è·å–"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            return response.text[:max_chars]
        except Exception as e:
            return f"Error fetching {url}: {e}"
    
    def fetch_domestic_news(self) -> List[Dict]:
        """è·å–å›½å†… AI èµ„è®¯"""
        news_items = []
        domestic = self.config.get("sources", {}).get("domestic", {})
        
        # 1. æ™ºè°± AI
        try:
            zhipu_html = self.fetch_url_content("https://www.zhipuai.cn/")
            # ç®€å•æå– GLM-5 ç­‰å…³é”®è¯ç›¸å…³å†…å®¹
            if "GLM-5" in zhipu_html or "GLM-4" in zhipu_html:
                news_items.append({
                    "title": "æ™ºè°± GLM-5 æ¨¡å‹åŠ¨æ€",
                    "source": "æ™ºè°± AI",
                    "link": "https://www.zhipuai.cn/",
                    "region": "domestic"
                })
        except:
            pass
        
        # 2. DeepSeek
        try:
            ds_html = self.fetch_url_content("https://api-docs.deepseek.com/")
            if "V3.2" in ds_html or "V3" in ds_html:
                news_items.append({
                    "title": "DeepSeek-V3.2 æ¨¡å‹æ›´æ–°",
                    "source": "DeepSeek",
                    "link": "https://www.deepseek.com/",
                    "region": "domestic"
                })
        except:
            pass
        
        # 3. é˜¿é‡Œé€šä¹‰
        try:
            news_items.append({
                "title": "é˜¿é‡Œé€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹åŠ¨æ€",
                "source": "é˜¿é‡Œé€šä¹‰",
                "link": "https://qwenlm.github.io/",
                "region": "domestic"
            })
        except:
            pass
        
        # 4. å­—èŠ‚è±†åŒ…
        try:
            news_items.append({
                "title": "å­—èŠ‚è±†åŒ…/äº‘é›€æ¨¡å‹æ›´æ–°",
                "source": "å­—èŠ‚è·³åŠ¨",
                "link": "https://www.doubao.com/",
                "region": "domestic"
            })
        except:
            pass
        
        # 5. Moonshot Kimi
        try:
            news_items.append({
                "title": "Kimi K2 ç³»åˆ—æ¨¡å‹åŠ¨æ€",
                "source": "Moonshot",
                "link": "https://kimi.moonshot.cn/",
                "region": "domestic"
            })
        except:
            pass
        
        return news_items
    
    def fetch_international_news(self) -> List[Dict]:
        """è·å–å›½é™… AI èµ„è®¯"""
        news_items = []
        
        # 1. TechCrunch Feed
        tc_news = self.fetch_techcrunch_feed()
        for item in tc_news:
            news_items.append({
                "title": item["title"],
                "source": "TechCrunch",
                "link": item["link"],
                "description": item["description"],
                "region": "international"
            })
        
        # 2. OpenAI
        try:
            news_items.append({
                "title": "OpenAI æœ€æ–°åŠ¨æ€ / GPT-5 / o1 ç³»åˆ—æ›´æ–°",
                "source": "OpenAI",
                "link": "https://openai.com/news",
                "region": "international"
            })
        except:
            pass
        
        # 3. Anthropic
        try:
            news_items.append({
                "title": "Anthropic Claude ç³»åˆ—æ¨¡å‹æ›´æ–°",
                "source": "Anthropic",
                "link": "https://www.anthropic.com/news",
                "region": "international"
            })
        except:
            pass
        
        # 4. Google AI
        try:
            news_items.append({
                "title": "Google Gemini ç³»åˆ—æ¨¡å‹åŠ¨æ€",
                "source": "Google",
                "link": "https://blog.google/technology/ai/",
                "region": "international"
            })
        except:
            pass
        
        # 5. xAI
        try:
            news_items.append({
                "title": "xAI Grok ç³»åˆ— / æ˜Ÿé™…æ•°æ®ä¸­å¿ƒè®¡åˆ’",
                "source": "xAI",
                "link": "https://x.ai",
                "region": "international"
            })
        except:
            pass
        
        return news_items
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ—©æŠ¥"""
        domestic_news = self.fetch_domestic_news()
        international_news = self.fetch_international_news()
        
        date_str = datetime.now().strftime("%Y-%m-%d")
        
        report = f"""ğŸŒ… æ—©æŠ¥ ({date_str})

## ğŸ‡¨ğŸ‡³ å›½å†… AI å¤´æ¡
"""
        
        if domestic_news:
            for i, item in enumerate(domestic_news[:5], 1):
                report += f"\n{i}. **{item['source']}** - {item['title']}\n"
                report += f"   ğŸ“ {item['link']}\n"
        else:
            report += "\næš‚æ— æœ€æ–°åŠ¨æ€\n"
        
        report += "\n## ğŸŒ å›½é™… AI å¤´æ¡\n"
        
        if international_news:
            for i, item in enumerate(international_news[:5], 1):
                report += f"\n{i}. **{item['source']}** - {item['title']}\n"
                if item.get('description'):
                    desc = item['description'][:100] + "..." if len(item['description']) > 100 else item['description']
                    report += f"   ğŸ“ {desc}\n"
                report += f"   ğŸ“ {item['link']}\n"
        else:
            report += "\næš‚æ— æœ€æ–°åŠ¨æ€\n"
        
        report += "\n## ğŸ“Š ä¸€å¥è¯æ€»ç»“\n"
        report += "> å›½å†…å¤–å¤§æ¨¡å‹æŒç»­è¿­ä»£ï¼ŒAI ç«äº‰è¿›å…¥ç™½çƒ­åŒ–é˜¶æ®µã€‚\n"
        
        return report

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    fetcher = NewsFetcher()
    report = fetcher.generate_report()
    print(report)

if __name__ == "__main__":
    main()
